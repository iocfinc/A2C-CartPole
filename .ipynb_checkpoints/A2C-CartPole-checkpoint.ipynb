{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2C - CartPole Agent\n",
    "\n",
    "This is an implementation of an _Advantage Actor-Critic method_ for solving the CartPole environment in OpenAI gym. Resource for this one is [the RLcode repo](https://github.com/rlcode/reinforcement-learning/blob/master/2-cartpole/4-actor-critic/cartpole_a2c.py). This is created so that we can see how to code an A2C agent and learn the basics first on what the general idea for the architecture is before applying it to more complex tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\icfernando\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "NOTE:\n",
    "This is an implementation of the Advantage actor-critic agent for Cartpole.\n",
    "The main source for this one would be in this repo: https://github.com/rlcode/reinforcement-learning/blob/master/2-cartpole/4-actor-critic/cartpole_a2c.py\n",
    "This was done by rlcode guys, similar to the one that gave us DQN-Cartpole earlier.\n",
    "'''\n",
    "\n",
    "# Import dependencies\n",
    "\n",
    "import sys\n",
    "import gym\n",
    "import pylab\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next step we will create the agent that we will be using. It will contain the functions for creating the model for both actor and critic. It will also include the function for the training as well as the function for getting the action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: Start of the Cartpole Agent using A2C (Advantage Actor-Critic)\n",
    "class A2CAgent:\n",
    "    def __init__(self, state_size, action_size,nodes):\n",
    "        self.render = False # For rendering the cartpole model\n",
    "        self.load_model = False # Set if you want to load a previous checkpoint\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.value_size = 1\n",
    "        self.nodes = nodes\n",
    "\n",
    "        # Policy Gradient hyperparameters\n",
    "        # NOTE: Read more on Policy Gradient\n",
    "\n",
    "        self.discount_factor = 0.99 # For the entire update statement\n",
    "        self.actor_lr = 0.001 # For the Optimizer of Actor\n",
    "        self.critic_lr = 0.005 # Why is it higher? For stability?\n",
    "\n",
    "        # Call the building blocks\n",
    "        self.actor = self.build_actor()\n",
    "        self.critic = self.build_critic()\n",
    "\n",
    "        # Check if we need to load a model\n",
    "        if self.load_model:\n",
    "            self.actor.load_weights(\"./save_model/cartpole_actor.h5\")\n",
    "            self.critic.load_weights(\"./save_model/cartpole_critic.h5\")\n",
    "    # We then create the Neural Network for the approximation of the actor and critic values\n",
    "    # i.e. policy and value for the model.\n",
    "\n",
    "    # NOTE: Actor module: Input of states and outputs the probability of an action (softmax)\n",
    "    def build_actor(self):\n",
    "        actor = Sequential() # Define our model\n",
    "        actor.add(Dense(self.nodes , input_dim = self.state_size, activation= 'relu', kernel_initializer= 'he_uniform'))\n",
    "        actor.add(Dense(self.action_size, activation='softmax',kernel_initializer='he_uniform'))\n",
    "        actor.summary()\n",
    "        actor.compile(loss = 'categorical_crossentropy', optimizer = Adam(lr = self.actor_lr))\n",
    "        return actor\n",
    "    # NOTE: Critic module: Input is also state but the output is also state(linear)\n",
    "    def build_critic(self):\n",
    "        critic = Sequential()\n",
    "        critic.add(Dense(self.nodes, input_dim = self.state_size, activation= 'relu', kernel_initializer= 'he_uniform'))\n",
    "        critic.add(Dense(self.value_size,activation= 'linear', kernel_initializer= 'he_uniform'))\n",
    "        critic.summary()\n",
    "        critic.compile(loss = 'mse', optimizer= Adam(lr=self.critic_lr))# Loss is MSE since we want to give out a value and not a probability.\n",
    "        return critic\n",
    "    # NOTE: We do the function on how the agent will pick the next action and policy based on stochastics(probability)\n",
    "    def get_action(self,state):\n",
    "        policy = self.actor.predict(state,batch_size=1).flatten()\n",
    "        return np.random.choice(self.action_size,1,p=policy)[0]\n",
    "    # NOTE: We do the update for the network policy.\n",
    "    def train_model(self, state, action, reward, next_state, done):\n",
    "        target = np.zeros((1,self.value_size)) # Initialize the policy targets matrix\n",
    "        advantages = np.zeros((1,self.action_size)) # Initialize the advantages matrix\n",
    "\n",
    "        value = self.critic.predict(state)[0] # Get value for this state\n",
    "        next_value = self.critic.predict(next_state)[0] # Get value for the next state\n",
    "\n",
    "        # update the advantages and value tables if done\n",
    "        if done:\n",
    "            advantages[0][action] = reward - value # Basically, what do we gain by choosing the action, will it improve or worsen the advantage\n",
    "            target[0][0] = reward # Fill in the target value to see if we can still improve it in the policy making\n",
    "        else:\n",
    "            advantages[0][action] = reward + self.discount_factor*(next_value) - value # If not yet done, then simply update for the current step.\n",
    "            target[0][0] = reward + self.discount_factor*next_value\n",
    "        # Once we are done with the episode, we then update the weights\n",
    "        self.actor.fit(state,advantages,epochs=1,verbose=0)\n",
    "        self.critic.fit(state,target,epochs=1,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fir the next section, we are creating a class for our training module. In the original source, this was simply run as is but in my case I wanted to reuse it to experiment on the effects of the number of nodes. We can actually edit this class so that you can specify everything for the agent like the lr for the actor and the critic, the discount factor as well. Also, you can actually define how many episodes you might want to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A2C_train:\n",
    "    def __init__(self, episodes,nodes):\n",
    "        self.Episodes = episodes\n",
    "        self.nodes = nodes\n",
    "        if __name__ == '__main__':\n",
    "            # TODO: Create an environment\n",
    "            env = gym.make('CartPole-v1')\n",
    "            # TODO: Get the action and state sizes\n",
    "            state_size = env.observation_space.shape[0]\n",
    "            action_size = env.action_space.n\n",
    "            # TODO: Make the agent by calling the function earlier\n",
    "            agent = A2CAgent(state_size,action_size,self.nodes)\n",
    "            # TODO: Initialize our scores and episodes list\n",
    "            scores, episodes = [], []\n",
    "\n",
    "            # TODO: Create the training loop\n",
    "            for e in range(self.Episodes):\n",
    "                done = False\n",
    "                score = 0\n",
    "                state = env.reset()\n",
    "                state = np.reshape(state,[1,state_size])\n",
    "\n",
    "                while not done:\n",
    "                    # Check if we want to render\n",
    "                    if agent.render:\n",
    "                        env.render()\n",
    "                    action = agent.get_action(state)\n",
    "                    next_state, reward, done, info = env.step(action)\n",
    "                    next_state = np.reshape(next_state,[1,state_size])\n",
    "                    # Give immediate penalty for an action that terminates the episode immediately, Since we want to maximize the time\n",
    "                    # Note that the max for the cartpole is 499 and it will reset, otherwise we keep the current score if it is not yet done, and if it ended we give a -100 reward\n",
    "                    reward = reward if not done or score == 499 else -100\n",
    "                    # We now train the model based on the results of our action taken\n",
    "                    agent.train_model(state,action,reward,next_state,done)\n",
    "                    score += reward\n",
    "                    state = next_state\n",
    "\n",
    "                    if done:\n",
    "                        score = score if score == 500.0 else score +100\n",
    "                        scores.append(score)\n",
    "                        episodes.append(e)\n",
    "                        pylab.plot(episodes,scores,'b')\n",
    "                        pylab.savefig(\"./save_graph/A2C-CartPole.png\")\n",
    "                        if np.mean(scores[-min(10, len(scores)):]) > 490:\n",
    "                            sys.exit()\n",
    "                if e % 50 ==0:\n",
    "                    agent.actor.save_weights(\"./save_model/cartpole_actor.h5\")\n",
    "                    agent.critic.save_weights(\"./save_model/cartpole_critic.h5\")   \n",
    "                    print(\"episode: {} score: {}\".format(e,score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "For the next sections we just check the results of the agent from the original 24 nodes, a very small 8 nodes and a very large 64 node NN. For the results, we refer to the original 24 node agent as the baseline. Note: I ran the original notebook at 1000 episodes but for this one it is set at 250 just to show that the model does train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 170\n",
      "Trainable params: 170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 145\n",
      "Trainable params: 145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "episode: 0 score: 24.0\n",
      "episode: 50 score: 17.0\n",
      "episode: 100 score: 50.0\n",
      "episode: 150 score: 75.0\n",
      "episode: 200 score: 46.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.A2C_train at 0x278b02ad9b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A2C_train(250,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 58\n",
      "Trainable params: 58\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7e560d5cebe6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mA2C_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-0ae558d7d09b>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, episodes, nodes)\u001b[0m\n\u001b[0;32m     32\u001b[0m                     \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m499\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                     \u001b[1;31m# We now train the model based on the results of our action taken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                     \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                     \u001b[0mscore\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                     \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-6331d0a0b188>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# Once we are done with the episode, we then update the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madvantages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2697\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_make_callable_from_options'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2698\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2699\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;31m# hack for list_devices() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1305\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m   1307\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1338\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m         \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "A2C_train(250,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 450\n",
      "Trainable params: 450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 385\n",
      "Trainable params: 385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "episode: 0 score: 15.0\n",
      "episode: 50 score: 32.0\n",
      "episode: 100 score: 75.0\n",
      "episode: 150 score: 122.0\n",
      "episode: 200 score: 95.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.A2C_train at 0x278ad5132e8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A2C_train(250,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the runtime for the 8 node agent will be quite long compared to the original 24 node agent. For the 64 node agent, it is also long. In theory it should be much longer than the 8 node but it does make up for it in the fact that it can actually get to the solution faster and be able to remember it. This is based on the graph results. If we look at the 24 node we can see the volatility although the trend is still increasing. For the 64 node, we can already see it peaking and maintaining it for some runs. While for the 8 node, it is just noisy and the trend is rather flat. The question now is why is it that the agent still gets erratic behaviour instead of a general solution? That is because we are using a stochastic approach for the implementation. If you look at the code, we used random choice with probability set as the policy. We are non-deterministic in a sense that we do not hardcode our policy so there will always be a time where our agent will try to do a weird move. This is in line with the exploration vs. exploitation method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
